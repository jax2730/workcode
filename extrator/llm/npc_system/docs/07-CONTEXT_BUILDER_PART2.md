# 07 - ä¸Šä¸‹æ–‡æ„å»ºè¯¦è§£ (ç¬¬2éƒ¨åˆ†)

## âš™ï¸ é«˜çº§ç‰¹æ€§

### 1. åŠ¨æ€é¢„ç®—è°ƒæ•´

æ ¹æ®å®é™…æƒ…å†µåŠ¨æ€è°ƒæ•´å„æ¥æºçš„tokené¢„ç®—ã€‚

```python
class AdaptiveContextBuilder(ContextBuilder):
    """è‡ªé€‚åº”ä¸Šä¸‹æ–‡æ„å»ºå™¨"""
    
    def adjust_budget(
        self,
        packets: List[ContextPacket],
        query: str
    ) -> Dict[str, float]:
        """
        åŠ¨æ€è°ƒæ•´é¢„ç®—åˆ†é…
        
        ç­–ç•¥:
        - å¦‚æœæŸä¸ªæ¥æºçš„ä¿¡æ¯ç‰¹åˆ«ç›¸å…³ï¼Œå¢åŠ å…¶é¢„ç®—
        - å¦‚æœæŸä¸ªæ¥æºæ²¡æœ‰ä¿¡æ¯ï¼Œå°†å…¶é¢„ç®—åˆ†é…ç»™å…¶ä»–æ¥æº
        """
        # ç»Ÿè®¡å„æ¥æºçš„ä¿¡æ¯é‡å’Œå¹³å‡ç›¸å…³æ€§
        source_stats = {}
        for packet in packets:
            source = packet.source
            if source not in source_stats:
                source_stats[source] = {
                    "count": 0,
                    "total_relevance": 0.0,
                    "total_tokens": 0
                }
            source_stats[source]["count"] += 1
            source_stats[source]["total_relevance"] += packet.relevance_score
            source_stats[source]["total_tokens"] += packet.token_count
        
        # è®¡ç®—å¹³å‡ç›¸å…³æ€§
        for source, stats in source_stats.items():
            if stats["count"] > 0:
                stats["avg_relevance"] = stats["total_relevance"] / stats["count"]
            else:
                stats["avg_relevance"] = 0.0
        
        # è°ƒæ•´é¢„ç®—
        adjusted_budget = {}
        base_budget = {
            "memory": self.config.memory_budget,
            "rag": self.config.rag_budget,
            "history": self.config.history_budget,
            "notes": self.config.notes_budget,
            "custom": self.config.custom_budget
        }
        
        # æ ¹æ®ç›¸å…³æ€§è°ƒæ•´
        total_relevance = sum(s["avg_relevance"] for s in source_stats.values())
        if total_relevance > 0:
            for source, stats in source_stats.items():
                weight = stats["avg_relevance"] / total_relevance
                # åŸºç¡€é¢„ç®— + ç›¸å…³æ€§åŠ æˆ
                adjusted_budget[source] = base_budget.get(source, 0.1) * (1 + weight)
        
        # å½’ä¸€åŒ–
        total = sum(adjusted_budget.values())
        if total > 0:
            adjusted_budget = {k: v/total for k, v in adjusted_budget.items()}
        
        return adjusted_budget
```

### 2. ä¸Šä¸‹æ–‡ç¼“å­˜

ç¼“å­˜æœ€è¿‘æ„å»ºçš„ä¸Šä¸‹æ–‡ï¼Œé¿å…é‡å¤è®¡ç®—ã€‚

```python
from functools import lru_cache
import hashlib

class CachedContextBuilder(ContextBuilder):
    """å¸¦ç¼“å­˜çš„ä¸Šä¸‹æ–‡æ„å»ºå™¨"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.cache = {}
        self.cache_ttl = 300  # 5åˆ†é’Ÿ
        self.cache_hits = 0
        self.cache_misses = 0
    
    def build_context(
        self,
        message: str,
        player_id: str,
        npc_id: str,
        **kwargs
    ) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡ (å¸¦ç¼“å­˜)"""
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = self._generate_cache_key(message, player_id, npc_id)
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.cache:
            cached_data = self.cache[cache_key]
            age = (datetime.now() - cached_data["timestamp"]).seconds
            
            if age < self.cache_ttl:
                self.cache_hits += 1
                return cached_data["context"]
        
        # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ„å»ºä¸Šä¸‹æ–‡
        self.cache_misses += 1
        context = super().build_context(message, player_id, npc_id, **kwargs)
        
        # å­˜å…¥ç¼“å­˜
        self.cache[cache_key] = {
            "context": context,
            "timestamp": datetime.now()
        }
        
        # æ¸…ç†è¿‡æœŸç¼“å­˜
        self._cleanup_cache()
        
        return context
    
    def _generate_cache_key(
        self,
        message: str,
        player_id: str,
        npc_id: str
    ) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # ä½¿ç”¨æ¶ˆæ¯çš„hash + player_id + npc_id
        msg_hash = hashlib.md5(message.encode()).hexdigest()[:8]
        return f"{npc_id}_{player_id}_{msg_hash}"
    
    def _cleanup_cache(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        now = datetime.now()
        expired_keys = []
        
        for key, data in self.cache.items():
            age = (now - data["timestamp"]).seconds
            if age >= self.cache_ttl:
                expired_keys.append(key)
        
        for key in expired_keys:
            del self.cache[key]
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        total = self.cache_hits + self.cache_misses
        hit_rate = self.cache_hits / total if total > 0 else 0
        
        return {
            "cache_size": len(self.cache),
            "cache_hits": self.cache_hits,
            "cache_misses": self.cache_misses,
            "hit_rate": f"{hit_rate:.2%}"
        }
```

### 3. å¹¶è¡Œä¿¡æ¯æ±‡é›†

ä½¿ç”¨å¼‚æ­¥å¹¶è¡ŒåŠ é€Ÿä¿¡æ¯æ±‡é›†ã€‚

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class AsyncContextBuilder(ContextBuilder):
    """å¼‚æ­¥ä¸Šä¸‹æ–‡æ„å»ºå™¨"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.executor = ThreadPoolExecutor(max_workers=4)
    
    async def gather_information_async(
        self,
        message: str,
        player_id: str,
        npc_id: str
    ) -> List[ContextPacket]:
        """å¼‚æ­¥æ±‡é›†ä¿¡æ¯"""
        tasks = []
        
        # 1. è®°å¿†æ£€ç´¢ (å¹¶è¡Œ)
        if self.memory_tool:
            tasks.append(self._search_memory_async(message, player_id))
        
        # 2. RAGæ£€ç´¢ (å¹¶è¡Œ)
        if self.rag_tool:
            tasks.append(self._search_rag_async(message))
        
        # 3. å¯¹è¯å†å² (å¹¶è¡Œ)
        if hasattr(self, 'dialogue_storage'):
            tasks.append(self._get_history_async(npc_id, player_id))
        
        # 4. å¥½æ„Ÿåº¦ä¿¡æ¯ (å¹¶è¡Œ)
        if self.relationship_manager:
            tasks.append(self._get_affinity_async(npc_id, player_id))
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks)
        
        # åˆå¹¶ç»“æœ
        all_packets = []
        for result in results:
            if result:
                all_packets.extend(result)
        
        return all_packets
    
    async def _search_memory_async(
        self,
        message: str,
        player_id: str
    ) -> List[ContextPacket]:
        """å¼‚æ­¥æœç´¢è®°å¿†"""
        loop = asyncio.get_event_loop()
        
        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥æ–¹æ³•
        packets = await loop.run_in_executor(
            self.executor,
            self._search_memory_sync,
            message,
            player_id
        )
        
        return packets
    
    def _search_memory_sync(
        self,
        message: str,
        player_id: str
    ) -> List[ContextPacket]:
        """åŒæ­¥æœç´¢è®°å¿† (åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ)"""
        packets = []
        
        # æœç´¢å„å±‚è®°å¿†
        for memory_type in ["working", "episodic", "semantic"]:
            results = self.memory_tool.execute(
                "search",
                query=message,
                memory_type=memory_type,
                user_id=player_id,
                limit=5
            )
            
            for mem in results:
                packets.append(ContextPacket(
                    content=mem.content,
                    source=f"memory_{memory_type}",
                    timestamp=mem.timestamp,
                    relevance_score=mem.relevance_score,
                    priority=7,
                    metadata={"memory_type": memory_type}
                ))
        
        return packets
    
    # ç±»ä¼¼åœ°å®ç°å…¶ä»–å¼‚æ­¥æ–¹æ³•...
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. Tokenä¼°ç®—ä¼˜åŒ–

ä½¿ç”¨æ›´ç²¾ç¡®çš„tokenè®¡æ•°å™¨ã€‚

```python
from transformers import AutoTokenizer

class PreciseContextBuilder(ContextBuilder):
    """ç²¾ç¡®tokenè®¡æ•°çš„ä¸Šä¸‹æ–‡æ„å»ºå™¨"""
    
    def __init__(self, *args, tokenizer_name="Qwen/Qwen2.5-7B", **kwargs):
        super().__init__(*args, **kwargs)
        
        # åŠ è½½tokenizer
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)
            self.use_precise_counting = True
        except Exception as e:
            print(f"[ContextBuilder] æ— æ³•åŠ è½½tokenizer: {e}")
            print("[ContextBuilder] ä½¿ç”¨ç®€åŒ–çš„tokenä¼°ç®—")
            self.tokenizer = None
            self.use_precise_counting = False
    
    def _estimate_tokens(self, text: str) -> int:
        """ç²¾ç¡®ä¼°ç®—tokenæ•°é‡"""
        if self.use_precise_counting and self.tokenizer:
            # ä½¿ç”¨çœŸå®çš„tokenizer
            tokens = self.tokenizer.encode(text)
            return len(tokens)
        else:
            # ç®€åŒ–ä¼°ç®—: 1 token â‰ˆ 1.5 å­—ç¬¦
            return int(len(text) / 1.5)
```

### 2. å¢é‡æ›´æ–°

åªæ›´æ–°å˜åŒ–çš„éƒ¨åˆ†ï¼Œé¿å…é‡æ–°æ„å»ºæ•´ä¸ªä¸Šä¸‹æ–‡ã€‚

```python
class IncrementalContextBuilder(ContextBuilder):
    """å¢é‡æ›´æ–°çš„ä¸Šä¸‹æ–‡æ„å»ºå™¨"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.last_context = {}  # {session_id: context_data}
    
    def build_context_incremental(
        self,
        message: str,
        player_id: str,
        npc_id: str,
        session_id: str
    ) -> str:
        """å¢é‡æ„å»ºä¸Šä¸‹æ–‡"""
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸Šæ¬¡çš„ä¸Šä¸‹æ–‡
        if session_id not in self.last_context:
            # é¦–æ¬¡æ„å»ºï¼Œå®Œæ•´æ„å»º
            context = self.build_context(message, player_id, npc_id)
            self.last_context[session_id] = {
                "context": context,
                "timestamp": datetime.now(),
                "message_count": 1
            }
            return context
        
        # å¢é‡æ›´æ–°
        last_data = self.last_context[session_id]
        
        # åªæ›´æ–°å˜åŒ–çš„éƒ¨åˆ†
        # 1. æ·»åŠ æ–°çš„å¯¹è¯å†å²
        new_history = f"ç”¨æˆ·: {message}\n"
        
        # 2. æ›´æ–°å·¥ä½œè®°å¿† (å¦‚æœæœ‰æ–°ä¿¡æ¯)
        new_memories = self._get_new_memories(message, player_id, last_data["timestamp"])
        
        # 3. é‡æ–°æ„å»ºä¸Šä¸‹æ–‡ (åªæ›´æ–°å˜åŒ–çš„éƒ¨åˆ†)
        context = self._update_context(
            last_data["context"],
            new_history=new_history,
            new_memories=new_memories
        )
        
        # æ›´æ–°ç¼“å­˜
        self.last_context[session_id] = {
            "context": context,
            "timestamp": datetime.now(),
            "message_count": last_data["message_count"] + 1
        }
        
        return context
```

### 3. æ‰¹é‡å¤„ç†

æ‰¹é‡å¤„ç†å¤šä¸ªè¯·æ±‚ï¼Œæé«˜ååé‡ã€‚

```python
class BatchContextBuilder(ContextBuilder):
    """æ‰¹é‡å¤„ç†çš„ä¸Šä¸‹æ–‡æ„å»ºå™¨"""
    
    def build_contexts_batch(
        self,
        requests: List[Dict[str, str]]
    ) -> List[str]:
        """
        æ‰¹é‡æ„å»ºä¸Šä¸‹æ–‡
        
        Args:
            requests: [
                {"message": "...", "player_id": "...", "npc_id": "..."},
                ...
            ]
        
        Returns:
            List[str]: ä¸Šä¸‹æ–‡åˆ—è¡¨
        """
        # 1. æ‰¹é‡æ±‡é›†ä¿¡æ¯
        all_packets = []
        for req in requests:
            packets = self.gather_information(
                req["message"],
                req["player_id"],
                req["npc_id"]
            )
            all_packets.append(packets)
        
        # 2. æ‰¹é‡é€‰æ‹©
        all_selected = []
        for packets, req in zip(all_packets, requests):
            selected = self.select_relevant(packets, req["message"])
            all_selected.append(selected)
        
        # 3. æ‰¹é‡ç»“æ„åŒ–
        contexts = []
        for selected, req in zip(all_selected, requests):
            context = self.structure_context(
                selected,
                req.get("npc_name", "NPC"),
                req["player_id"]
            )
            contexts.append(context)
        
        return contexts
```

---

## ğŸ› è°ƒè¯•å’Œç›‘æ§

### 1. è¯¦ç»†æ—¥å¿—

```python
import logging

class LoggingContextBuilder(ContextBuilder):
    """å¸¦è¯¦ç»†æ—¥å¿—çš„ä¸Šä¸‹æ–‡æ„å»ºå™¨"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.logger = logging.getLogger("ContextBuilder")
        self.logger.setLevel(logging.DEBUG)
    
    def build_context(self, message, player_id, npc_id, **kwargs):
        """æ„å»ºä¸Šä¸‹æ–‡ (å¸¦æ—¥å¿—)"""
        self.logger.info(f"å¼€å§‹æ„å»ºä¸Šä¸‹æ–‡: npc={npc_id}, player={player_id}")
        
        # 1. Gather
        start_time = time.time()
        packets = self.gather_information(message, player_id, npc_id)
        gather_time = time.time() - start_time
        self.logger.debug(f"Gatherå®Œæˆ: {len(packets)}ä¸ªä¿¡æ¯åŒ…, è€—æ—¶{gather_time:.3f}s")
        
        # è®°å½•å„æ¥æºçš„ä¿¡æ¯é‡
        source_counts = {}
        for p in packets:
            source_counts[p.source] = source_counts.get(p.source, 0) + 1
        self.logger.debug(f"ä¿¡æ¯æ¥æºåˆ†å¸ƒ: {source_counts}")
        
        # 2. Select
        start_time = time.time()
        selected = self.select_relevant(packets, message)
        select_time = time.time() - start_time
        self.logger.debug(f"Selectå®Œæˆ: é€‰ä¸­{len(selected)}/{len(packets)}ä¸ª, è€—æ—¶{select_time:.3f}s")
        
        # è®°å½•é€‰ä¸­çš„ä¿¡æ¯
        total_tokens = sum(p.token_count for p in selected)
        self.logger.debug(f"é€‰ä¸­ä¿¡æ¯æ€»tokenæ•°: {total_tokens}")
        
        # 3. Structure
        start_time = time.time()
        context = self.structure_context(selected, npc_id, player_id)
        structure_time = time.time() - start_time
        self.logger.debug(f"Structureå®Œæˆ: è€—æ—¶{structure_time:.3f}s")
        
        # 4. Compress (å¦‚æœéœ€è¦)
        context_tokens = self._estimate_tokens(context)
        max_tokens = int(self.config.max_tokens * (1 - self.config.reserve_ratio))
        
        if context_tokens > max_tokens:
            self.logger.warning(f"ä¸Šä¸‹æ–‡è¶…é•¿: {context_tokens} > {max_tokens}, å¼€å§‹å‹ç¼©")
            start_time = time.time()
            context = self.compress_context(context, max_tokens)
            compress_time = time.time() - start_time
            compressed_tokens = self._estimate_tokens(context)
            self.logger.info(f"å‹ç¼©å®Œæˆ: {context_tokens} â†’ {compressed_tokens}, è€—æ—¶{compress_time:.3f}s")
        
        total_time = gather_time + select_time + structure_time
        self.logger.info(f"ä¸Šä¸‹æ–‡æ„å»ºå®Œæˆ: æ€»è€—æ—¶{total_time:.3f}s")
        
        return context
```

### 2. æ€§èƒ½ç›‘æ§

```python
class MonitoredContextBuilder(ContextBuilder):
    """å¸¦æ€§èƒ½ç›‘æ§çš„ä¸Šä¸‹æ–‡æ„å»ºå™¨"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.metrics = {
            "build_count": 0,
            "total_time": 0.0,
            "gather_time": 0.0,
            "select_time": 0.0,
            "structure_time": 0.0,
            "compress_time": 0.0,
            "avg_packets": 0,
            "avg_selected": 0,
            "avg_tokens": 0,
            "compression_count": 0
        }
    
    def build_context(self, message, player_id, npc_id, **kwargs):
        """æ„å»ºä¸Šä¸‹æ–‡ (å¸¦ç›‘æ§)"""
        start_time = time.time()
        
        # Gather
        gather_start = time.time()
        packets = self.gather_information(message, player_id, npc_id)
        self.metrics["gather_time"] += time.time() - gather_start
        
        # Select
        select_start = time.time()
        selected = self.select_relevant(packets, message)
        self.metrics["select_time"] += time.time() - select_start
        
        # Structure
        structure_start = time.time()
        context = self.structure_context(selected, npc_id, player_id)
        self.metrics["structure_time"] += time.time() - structure_start
        
        # Compress (å¦‚æœéœ€è¦)
        context_tokens = self._estimate_tokens(context)
        max_tokens = int(self.config.max_tokens * (1 - self.config.reserve_ratio))
        
        if context_tokens > max_tokens:
            compress_start = time.time()
            context = self.compress_context(context, max_tokens)
            self.metrics["compress_time"] += time.time() - compress_start
            self.metrics["compression_count"] += 1
        
        # æ›´æ–°ç»Ÿè®¡
        self.metrics["build_count"] += 1
        self.metrics["total_time"] += time.time() - start_time
        self.metrics["avg_packets"] = (
            (self.metrics["avg_packets"] * (self.metrics["build_count"] - 1) + len(packets)) /
            self.metrics["build_count"]
        )
        self.metrics["avg_selected"] = (
            (self.metrics["avg_selected"] * (self.metrics["build_count"] - 1) + len(selected)) /
            self.metrics["build_count"]
        )
        self.metrics["avg_tokens"] = (
            (self.metrics["avg_tokens"] * (self.metrics["build_count"] - 1) + context_tokens) /
            self.metrics["build_count"]
        )
        
        return context
    
    def get_metrics(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        count = self.metrics["build_count"]
        if count == 0:
            return self.metrics
        
        return {
            "build_count": count,
            "avg_total_time": self.metrics["total_time"] / count,
            "avg_gather_time": self.metrics["gather_time"] / count,
            "avg_select_time": self.metrics["select_time"] / count,
            "avg_structure_time": self.metrics["structure_time"] / count,
            "avg_compress_time": self.metrics["compress_time"] / count if self.metrics["compression_count"] > 0 else 0,
            "avg_packets": self.metrics["avg_packets"],
            "avg_selected": self.metrics["avg_selected"],
            "avg_tokens": self.metrics["avg_tokens"],
            "compression_rate": self.metrics["compression_count"] / count
        }
```

---

## ğŸ”— ä¸å…¶ä»–æ¨¡å—çš„é›†æˆ

### åœ¨ NPCAgent ä¸­ä½¿ç”¨

```python
class NPCAgent:
    def __init__(self, ...):
        # åˆ›å»ºä¸Šä¸‹æ–‡æ„å»ºå™¨
        self.context_builder = ContextBuilder(
            config=ContextConfig(
                max_tokens=3000,
                role_description=self.personality.to_prompt()
            ),
            memory_tool=self.memory,
            rag_tool=self.rag,
            relationship_manager=self.relationship
        )
    
    def chat(self, player_id: str, message: str, ...):
        # 1. æ„å»ºä¸Šä¸‹æ–‡
        context = self.context_builder.build_context(
            message=message,
            player_id=player_id,
            npc_id=self.npc_id
        )
        
        # 2. å‘é€ç»™LLM
        response = self.llm.invoke([
            {"role": "system", "content": context},
            {"role": "user", "content": message}
        ])
        
        return response.content
```

---

## ğŸ“š æœ€ä½³å®è·µ

### 1. åˆç†è®¾ç½®tokené¢„ç®—

```python
# æ¨èé…ç½®
config = ContextConfig(
    max_tokens=3000,
    reserve_ratio=0.2,  # é¢„ç•™20%ç»™ç³»ç»ŸæŒ‡ä»¤å’Œå›å¤
    
    # é¢„ç®—åˆ†é… (æ€»å’Œ=1.0)
    memory_budget=0.30,    # è®°å¿†30% (æœ€é‡è¦)
    rag_budget=0.25,       # RAG 25%
    history_budget=0.20,   # å†å²20%
    notes_budget=0.10,     # ç¬”è®°10%
    custom_budget=0.15     # è‡ªå®šä¹‰15%
)
```

### 2. ä¼˜å…ˆçº§è®¾ç½®

```python
ä¼˜å…ˆçº§å»ºè®®:
10: è§’è‰²è®¾å®š (system)
9:  å…³é”®æŒ‡ä»¤
8:  å·¥ä½œè®°å¿† (å½“å‰å¯¹è¯)
7:  æƒ…æ™¯è®°å¿†ã€å¯¹è¯å†å²ã€å¥½æ„Ÿåº¦
6:  è¯­ä¹‰è®°å¿†ã€RAGçŸ¥è¯†
5:  æ„ŸçŸ¥è®°å¿†ã€ç¬”è®°
4:  è‡ªå®šä¹‰ä¿¡æ¯
```

### 3. å‹ç¼©ç­–ç•¥

```python
# å¯ç”¨å‹ç¼©
config.enable_compression = True
config.compression_ratio = 0.7  # ä¿ç•™70%

# å‹ç¼©é¡ºåº (ä»ä½åˆ°é«˜ä¼˜å…ˆçº§)
compression_order = [
    "notes",           # æœ€å…ˆå‹ç¼©
    "custom",
    "perceptual",
    "semantic",
    "rag",
    "episodic",
    "history",
    "working",
    "relationship",
    "system"           # æœ€åå‹ç¼© (é€šå¸¸ä¸å‹ç¼©)
]
```

---

## ğŸ“ æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **GSSCæµæ°´çº¿**: Gather â†’ Select â†’ Structure â†’ Compress
2. **æ™ºèƒ½é€‰æ‹©**: åŸºäºç›¸å…³æ€§ã€æ—¶é—´ã€ä¼˜å…ˆçº§çš„ç»¼åˆè¯„åˆ†
3. **é¢„ç®—ç®¡ç†**: ä¸ºä¸åŒæ¥æºåˆ†é…tokené¢„ç®—
4. **å…œåº•å‹ç¼©**: è¶…å‡ºé™åˆ¶æ—¶æ™ºèƒ½å‹ç¼©

### æ€§èƒ½ä¼˜åŒ–

1. **ç¼“å­˜**: ç¼“å­˜æœ€è¿‘çš„ä¸Šä¸‹æ–‡
2. **å¹¶è¡Œ**: å¹¶è¡Œæ±‡é›†ä¿¡æ¯
3. **å¢é‡**: å¢é‡æ›´æ–°ä¸Šä¸‹æ–‡
4. **æ‰¹é‡**: æ‰¹é‡å¤„ç†è¯·æ±‚

### ç›‘æ§è°ƒè¯•

1. **è¯¦ç»†æ—¥å¿—**: è®°å½•æ¯ä¸ªé˜¶æ®µçš„è€—æ—¶
2. **æ€§èƒ½æŒ‡æ ‡**: ç»Ÿè®¡å¹³å‡è€—æ—¶å’Œtokenæ•°
3. **å¯è§†åŒ–**: å¯è§†åŒ–ä¸Šä¸‹æ–‡æ„å»ºè¿‡ç¨‹

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [05-è®°å¿†ç³»ç»Ÿè¯¦è§£](./05-MEMORY_SYSTEM.md) - è®°å¿†æ£€ç´¢
- [06-RAGç³»ç»Ÿè¯¦è§£](./06-RAG_SYSTEM.md) - çŸ¥è¯†æ£€ç´¢
- [08-å¥½æ„Ÿåº¦ç³»ç»Ÿè¯¦è§£](./08-RELATIONSHIP_SYSTEM.md) - å…³ç³»ä¿¡æ¯
- [10-NPCæ™ºèƒ½ä½“è¯¦è§£](./10-NPC_AGENT.md) - é›†æˆä½¿ç”¨

---

æ­å–œï¼ä½ ç°åœ¨å·²ç»å®Œå…¨æŒæ¡äº†ä¸Šä¸‹æ–‡æ„å»ºç³»ç»Ÿï¼ğŸ‰
