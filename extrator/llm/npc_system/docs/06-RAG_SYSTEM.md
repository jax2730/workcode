# 06 - RAGç³»ç»Ÿè¯¦è§£ (ç¬¬1éƒ¨åˆ†)

RAG (Retrieval-Augmented Generation) æ˜¯"æ£€ç´¢å¢å¼ºç”Ÿæˆ"ï¼Œè®©NPCèƒ½å¤Ÿä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ä¿¡æ¯æ¥å›ç­”é—®é¢˜ã€‚

## ğŸ¯ ä»€ä¹ˆæ˜¯RAGï¼Ÿ

### ç®€å•æ¯”å–»
æƒ³è±¡ä½ åœ¨è€ƒè¯•ï¼š
- **æ²¡æœ‰RAG**: åªèƒ½é è®°å¿†å›ç­”ï¼ˆå¯èƒ½è®°ä¸å…¨æˆ–è®°é”™ï¼‰
- **æœ‰RAG**: å¯ä»¥æŸ¥ä¹¦å›ç­”ï¼ˆå‡†ç¡®ã€è¯¦ç»†ã€å¯é ï¼‰

NPCçš„RAGç³»ç»Ÿå°±åƒç»™NPCé…äº†ä¸€ä¸ª"å›¾ä¹¦é¦†"ï¼

### æ ¸å¿ƒæ¦‚å¿µ
```
ç”¨æˆ·é—®é¢˜: "å¦‚ä½•é”»é€ é“å‰‘ï¼Ÿ"
    â†“
RAGç³»ç»Ÿæ£€ç´¢çŸ¥è¯†åº“
    â†“
æ‰¾åˆ°ç›¸å…³æ–‡æ¡£: "é“å‰‘é”»é€ æ•™ç¨‹.md"
    â†“
æå–ç›¸å…³æ®µè½
    â†“
LLMåŸºäºæ–‡æ¡£ç”Ÿæˆå›ç­”
    â†“
NPCå›å¤: "éœ€è¦3å—é“é”­å’Œ1æ ¹æœ¨æ£..."
```

---

## ğŸ—ï¸ RAGç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAGç³»ç»Ÿ                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚  æ–‡æ¡£åŠ è½½å™¨   â”‚  â† è¯»å–txt/md/jsonæ–‡ä»¶                â”‚
â”‚  â”‚ Document     â”‚                                       â”‚
â”‚  â”‚ Loader       â”‚                                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚         â†“                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚  æ–‡æ¡£å¤„ç†å™¨   â”‚  â† åˆ†å—ã€æ¸…æ´—ã€å…ƒæ•°æ®æå–             â”‚
â”‚  â”‚ Document     â”‚                                       â”‚
â”‚  â”‚ Processor    â”‚                                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚         â†“                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚  å‘é‡åŒ–æœåŠ¡   â”‚  â† æ–‡æœ¬â†’å‘é‡ (å¯é€‰)                   â”‚
â”‚  â”‚ Embedding    â”‚                                       â”‚
â”‚  â”‚ Service      â”‚                                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚         â†“                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚  å‘é‡å­˜å‚¨     â”‚  â† FAISSç´¢å¼• (å¯é€‰)                   â”‚
â”‚  â”‚ Vector       â”‚    æˆ–ä½™å¼¦ç›¸ä¼¼åº¦ (å¤‡ç”¨)                 â”‚
â”‚  â”‚ Store        â”‚                                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚         â†“                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚  æ£€ç´¢å™¨       â”‚  â† ç›¸ä¼¼åº¦æœç´¢ + é‡æ’åº                â”‚
â”‚  â”‚ Retriever    â”‚                                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 1. æ–‡æ¡£åŠ è½½å™¨ (Document Loader)

#### åŠŸèƒ½
ä»æ–‡ä»¶ç³»ç»ŸåŠ è½½æ–‡æ¡£åˆ°å†…å­˜ã€‚

#### æ”¯æŒæ ¼å¼
```python
æ”¯æŒçš„æ–‡ä»¶æ ¼å¼:
â”œâ”€â”€ .txt  - çº¯æ–‡æœ¬
â”œâ”€â”€ .md   - Markdown
â”œâ”€â”€ .json - JSONæ•°æ®
â”œâ”€â”€ .pdf  - PDFæ–‡æ¡£ (éœ€è¦é¢å¤–åº“)
â””â”€â”€ .docx - Wordæ–‡æ¡£ (éœ€è¦é¢å¤–åº“)
```

#### ä»£ç ç¤ºä¾‹
```python
from npc_system import RAGTool, RAGConfig

# åˆ›å»ºRAGå·¥å…·
rag = RAGTool(RAGConfig(
    knowledge_base_dir="./npc_data/knowledge_base/blacksmith",
    index_dir="./npc_data/rag_index/blacksmith"
))

# åŠ è½½å•ä¸ªæ–‡æ¡£
doc = rag.load_document("é“å‰‘é”»é€ æ•™ç¨‹.md")
print(doc.content)
print(doc.metadata)

# æ‰¹é‡åŠ è½½ç›®å½•ä¸‹æ‰€æœ‰æ–‡æ¡£
docs = rag.load_documents_from_dir("./knowledge_base/")
print(f"åŠ è½½äº† {len(docs)} ä¸ªæ–‡æ¡£")
```

#### æ–‡æ¡£ç»“æ„
```python
class Document:
    """æ–‡æ¡£å¯¹è±¡"""
    doc_id: str              # æ–‡æ¡£ID
    content: str             # æ–‡æ¡£å†…å®¹
    metadata: dict           # å…ƒæ•°æ®
    chunks: List[str]        # åˆ†å—åçš„å†…å®¹
    embedding: np.ndarray    # å‘é‡åµŒå…¥(å¯é€‰)
```

#### å…ƒæ•°æ®æå–
```python
# ä»æ–‡ä»¶åæå–å…ƒæ•°æ®
æ–‡ä»¶: "é“å‰‘é”»é€ æ•™ç¨‹_åŸºç¡€_2024.md"
å…ƒæ•°æ®: {
    "title": "é“å‰‘é”»é€ æ•™ç¨‹",
    "category": "åŸºç¡€",
    "year": "2024",
    "file_type": "md",
    "file_size": 1024,
    "created_at": "2024-01-15"
}

# ä»Markdownå‰ç½®å…ƒæ•°æ®æå–
---
title: é“å‰‘é”»é€ æ•™ç¨‹
author: è€é“åŒ 
difficulty: åŸºç¡€
tags: [é”»é€ , æ­¦å™¨, é“å‰‘]
---

å…ƒæ•°æ®: {
    "title": "é“å‰‘é”»é€ æ•™ç¨‹",
    "author": "è€é“åŒ ",
    "difficulty": "åŸºç¡€",
    "tags": ["é”»é€ ", "æ­¦å™¨", "é“å‰‘"]
}
```

---

### 2. æ–‡æ¡£å¤„ç†å™¨ (Document Processor)

#### åŠŸèƒ½
å°†é•¿æ–‡æ¡£åˆ†å—ã€æ¸…æ´—ã€æ ‡å‡†åŒ–ã€‚

#### ä¸ºä»€ä¹ˆè¦åˆ†å—ï¼Ÿ
```
é—®é¢˜: æ–‡æ¡£å¤ªé•¿ (5000å­—)
     â†“
LLMä¸Šä¸‹æ–‡é™åˆ¶ (åªèƒ½å¤„ç†2000 tokens)
     â†“
è§£å†³: å°†æ–‡æ¡£åˆ†æˆå°å— (æ¯å—500å­—)
     â†“
åªæ£€ç´¢ç›¸å…³çš„å—ï¼Œè€Œä¸æ˜¯æ•´ä¸ªæ–‡æ¡£
```

#### åˆ†å—ç­–ç•¥

**ç­–ç•¥1: å›ºå®šé•¿åº¦åˆ†å—**
```python
# æ¯500å­—ä¸€å—ï¼Œé‡å 100å­—
chunks = processor.chunk_by_length(
    text=document.content,
    chunk_size=500,
    overlap=100
)

# ç¤ºä¾‹:
# å—1: [0:500]
# å—2: [400:900]   â† ä¸å—1é‡å 100å­—
# å—3: [800:1300]  â† ä¸å—2é‡å 100å­—
```

**ç­–ç•¥2: è¯­ä¹‰åˆ†å—**
```python
# æŒ‰æ®µè½åˆ†å—
chunks = processor.chunk_by_paragraph(text)

# æŒ‰ç« èŠ‚åˆ†å—
chunks = processor.chunk_by_section(text)

# æŒ‰å¥å­åˆ†å—
chunks = processor.chunk_by_sentence(text, sentences_per_chunk=5)
```

**ç­–ç•¥3: æ™ºèƒ½åˆ†å—**
```python
# æ ¹æ®å†…å®¹è‡ªåŠ¨é€‰æ‹©åˆ†å—ç‚¹
chunks = processor.smart_chunk(
    text=document.content,
    max_chunk_size=500,
    prefer_boundaries=["\\n\\n", "ã€‚", "ï¼", "ï¼Ÿ"]  # ä¼˜å…ˆåœ¨è¿™äº›ä½ç½®åˆ†å—
)
```

#### ä»£ç ç¤ºä¾‹
```python
from npc_system.rag_tool import DocumentProcessor

processor = DocumentProcessor()

# åŠ è½½æ–‡æ¡£
with open("é“å‰‘é”»é€ æ•™ç¨‹.md", "r", encoding="utf-8") as f:
    text = f.read()

# åˆ†å—
chunks = processor.chunk_by_length(
    text=text,
    chunk_size=500,
    overlap=100
)

print(f"æ–‡æ¡£è¢«åˆ†æˆ {len(chunks)} å—")

for i, chunk in enumerate(chunks):
    print(f"\\n=== å— {i+1} ===")
    print(chunk[:100] + "...")
```

#### æ–‡æœ¬æ¸…æ´—
```python
# æ¸…æ´—æ–‡æœ¬
cleaned = processor.clean_text(text)

# æ¸…æ´—æ“ä½œ:
# 1. ç§»é™¤å¤šä½™ç©ºç™½
# 2. ç»Ÿä¸€æ¢è¡Œç¬¦
# 3. ç§»é™¤ç‰¹æ®Šå­—ç¬¦
# 4. æ ‡å‡†åŒ–æ ‡ç‚¹
# 5. ç§»é™¤HTMLæ ‡ç­¾ (å¦‚æœæœ‰)
```

---

### 3. å‘é‡åŒ–æœåŠ¡ (Embedding Service)

#### åŠŸèƒ½
å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼å‘é‡ï¼Œç”¨äºç›¸ä¼¼åº¦è®¡ç®—ã€‚

#### ä»€ä¹ˆæ˜¯å‘é‡åµŒå…¥ï¼Ÿ
```
æ–‡æœ¬: "é“å‰‘éœ€è¦3å—é“é”­"
  â†“ å‘é‡åŒ–
å‘é‡: [0.23, -0.45, 0.67, ..., 0.12]  (768ç»´)

æ–‡æœ¬: "é”»é€ é“å‰‘éœ€è¦é“é”­"
  â†“ å‘é‡åŒ–
å‘é‡: [0.25, -0.43, 0.65, ..., 0.15]  (768ç»´)

ç›¸ä¼¼åº¦è®¡ç®—:
cos_sim(å‘é‡1, å‘é‡2) = 0.95  â† éå¸¸ç›¸ä¼¼ï¼
```

#### åµŒå…¥æ¨¡å‹é€‰æ‹©

**é€‰é¡¹1: æœ¬åœ°æ¨¡å‹ (æ¨è)**
```python
# ä½¿ç”¨Ollamaçš„åµŒå…¥æ¨¡å‹
from langchain_ollama import OllamaEmbeddings

embeddings = OllamaEmbeddings(
    model="nomic-embed-text"  # è½»é‡çº§åµŒå…¥æ¨¡å‹
)

# åµŒå…¥å•ä¸ªæ–‡æœ¬
vector = embeddings.embed_query("é“å‰‘é”»é€ ")
print(f"å‘é‡ç»´åº¦: {len(vector)}")  # 768

# æ‰¹é‡åµŒå…¥
vectors = embeddings.embed_documents([
    "é“å‰‘é”»é€ æ•™ç¨‹",
    "ç²¾é’¢å‰‘åˆ¶ä½œæ–¹æ³•",
    "æ­¦å™¨ç»´æŠ¤æŒ‡å—"
])
```

**é€‰é¡¹2: ç®€å•åµŒå…¥ (å¤‡ç”¨)**
```python
# ä¸ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä½¿ç”¨TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer()
vectors = vectorizer.fit_transform([
    "é“å‰‘é”»é€ æ•™ç¨‹",
    "ç²¾é’¢å‰‘åˆ¶ä½œæ–¹æ³•"
])
```

**é€‰é¡¹3: æ— åµŒå…¥ (æœ€ç®€å•)**
```python
# ç›´æ¥ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ (åŸºäºè¯é¢‘)
# ä¸éœ€è¦é¢„è®­ç»ƒæ¨¡å‹ï¼Œé€Ÿåº¦å¿«ä½†æ•ˆæœä¸€èˆ¬
```

#### ä»£ç ç¤ºä¾‹
```python
from npc_system import RAGTool, RAGConfig

# é…ç½®RAG (å¯ç”¨åµŒå…¥)
config = RAGConfig(
    knowledge_base_dir="./knowledge_base",
    enable_embedding=True,
    embedding_model="nomic-embed-text"
)

rag = RAGTool(config)

# æ·»åŠ æ–‡æ¡£ (è‡ªåŠ¨åµŒå…¥)
rag.add_document(
    content="é“å‰‘éœ€è¦3å—é“é”­å’Œ1æ ¹æœ¨æ£åˆ¶ä½œ...",
    doc_id="ironsword_tutorial"
)

# æœç´¢ (ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦)
results = rag.search("å¦‚ä½•åˆ¶ä½œé“å‰‘", top_k=3)
```

---

### 4. å‘é‡å­˜å‚¨ (Vector Store)

#### åŠŸèƒ½
å­˜å‚¨å’Œæ£€ç´¢å‘é‡ï¼Œæ”¯æŒé«˜æ•ˆçš„ç›¸ä¼¼åº¦æœç´¢ã€‚

#### FAISSç´¢å¼•

**ä»€ä¹ˆæ˜¯FAISSï¼Ÿ**
- Facebookå¼€å‘çš„å‘é‡æ£€ç´¢åº“
- æ”¯æŒç™¾ä¸‡çº§å‘é‡çš„å¿«é€Ÿæœç´¢
- æ”¯æŒGPUåŠ é€Ÿ

**å®‰è£…FAISS**
```bash
# CPUç‰ˆæœ¬
pip install faiss-cpu

# GPUç‰ˆæœ¬ (å¦‚æœæœ‰NVIDIA GPU)
pip install faiss-gpu
```

**ä½¿ç”¨FAISS**
```python
import faiss
import numpy as np

# åˆ›å»ºç´¢å¼•
dimension = 768  # å‘é‡ç»´åº¦
index = faiss.IndexFlatL2(dimension)  # L2è·ç¦»ç´¢å¼•

# æ·»åŠ å‘é‡
vectors = np.random.random((100, dimension)).astype('float32')
index.add(vectors)

# æœç´¢
query_vector = np.random.random((1, dimension)).astype('float32')
distances, indices = index.search(query_vector, k=5)

print(f"æœ€ç›¸ä¼¼çš„5ä¸ªæ–‡æ¡£ç´¢å¼•: {indices[0]}")
print(f"è·ç¦»: {distances[0]}")
```

**ç´¢å¼•ç±»å‹**
```python
# 1. ç²¾ç¡®æœç´¢ (å°æ•°æ®é›†)
index = faiss.IndexFlatL2(dimension)

# 2. IVFç´¢å¼• (ä¸­ç­‰æ•°æ®é›†)
quantizer = faiss.IndexFlatL2(dimension)
index = faiss.IndexIVFFlat(quantizer, dimension, 100)  # 100ä¸ªèšç±»

# 3. HNSWç´¢å¼• (å¤§æ•°æ®é›†)
index = faiss.IndexHNSWFlat(dimension, 32)  # 32ä¸ªé‚»å±…
```

#### å¤‡ç”¨æ–¹æ¡ˆ: ä½™å¼¦ç›¸ä¼¼åº¦

**ä¸ä½¿ç”¨FAISSæ—¶**
```python
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

class SimpleVectorStore:
    def __init__(self):
        self.vectors = []
        self.doc_ids = []
    
    def add(self, vector, doc_id):
        self.vectors.append(vector)
        self.doc_ids.append(doc_id)
    
    def search(self, query_vector, top_k=5):
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = cosine_similarity(
            [query_vector],
            self.vectors
        )[0]
        
        # æ’åº
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            results.append({
                "doc_id": self.doc_ids[idx],
                "score": similarities[idx]
            })
        
        return results
```

---

### 5. æ£€ç´¢å™¨ (Retriever)

#### åŠŸèƒ½
æ ¹æ®æŸ¥è¯¢æ£€ç´¢æœ€ç›¸å…³çš„æ–‡æ¡£å—ã€‚

#### æ£€ç´¢æµç¨‹
```
ç”¨æˆ·æŸ¥è¯¢: "å¦‚ä½•é”»é€ é“å‰‘ï¼Ÿ"
    â†“
1. æŸ¥è¯¢å‘é‡åŒ–
   query_vector = embed("å¦‚ä½•é”»é€ é“å‰‘ï¼Ÿ")
    â†“
2. å‘é‡æœç´¢
   top_docs = vector_store.search(query_vector, k=10)
    â†“
3. é‡æ’åº (å¯é€‰)
   - è€ƒè™‘æ–‡æ¡£å…ƒæ•°æ® (æ—¥æœŸã€ä½œè€…ã€æ ‡ç­¾)
   - è€ƒè™‘æ–‡æ¡£è´¨é‡
   - è€ƒè™‘å¤šæ ·æ€§
    â†“
4. è¿”å›Top-Kç»“æœ
   results = top_docs[:5]
```

#### æ£€ç´¢ç­–ç•¥

**ç­–ç•¥1: çº¯å‘é‡æ£€ç´¢**
```python
results = rag.search(
    query="å¦‚ä½•é”»é€ é“å‰‘",
    method="vector",
    top_k=5
)
```

**ç­–ç•¥2: å…³é”®è¯æ£€ç´¢**
```python
results = rag.search(
    query="é“å‰‘ é”»é€ ",
    method="keyword",
    top_k=5
)
```

**ç­–ç•¥3: æ··åˆæ£€ç´¢**
```python
# ç»“åˆå‘é‡å’Œå…³é”®è¯
results = rag.search(
    query="å¦‚ä½•é”»é€ é“å‰‘",
    method="hybrid",
    vector_weight=0.7,    # å‘é‡æƒé‡
    keyword_weight=0.3,   # å…³é”®è¯æƒé‡
    top_k=5
)
```

**ç­–ç•¥4: å…ƒæ•°æ®è¿‡æ»¤**
```python
# å…ˆè¿‡æ»¤ï¼Œå†æ£€ç´¢
results = rag.search(
    query="é”»é€ æ–¹æ³•",
    filters={
        "category": "æ­¦å™¨åˆ¶ä½œ",
        "difficulty": "åŸºç¡€",
        "author": "è€é“åŒ "
    },
    top_k=5
)
```

#### é‡æ’åº

**ä¸ºä»€ä¹ˆéœ€è¦é‡æ’åºï¼Ÿ**
```
åˆå§‹æ£€ç´¢ç»“æœ (ä»…åŸºäºç›¸ä¼¼åº¦):
1. æ–‡æ¡£A: ç›¸ä¼¼åº¦0.95, ä½†æ˜¯è¿‡æ—¶çš„ä¿¡æ¯
2. æ–‡æ¡£B: ç›¸ä¼¼åº¦0.92, æœ€æ–°çš„æ•™ç¨‹
3. æ–‡æ¡£C: ç›¸ä¼¼åº¦0.90, æƒå¨ä½œè€…

é‡æ’åºå (è€ƒè™‘å¤šä¸ªå› ç´ ):
1. æ–‡æ¡£B: ç»¼åˆå¾—åˆ†0.96 (æœ€æ–° + é«˜ç›¸ä¼¼åº¦)
2. æ–‡æ¡£C: ç»¼åˆå¾—åˆ†0.94 (æƒå¨ + é«˜ç›¸ä¼¼åº¦)
3. æ–‡æ¡£A: ç»¼åˆå¾—åˆ†0.85 (è¿‡æ—¶ - æ‰£åˆ†)
```

**é‡æ’åºç®—æ³•**
```python
def rerank(results, query, metadata_weights):
    """
    é‡æ’åºç®—æ³•
    
    ç»¼åˆå¾—åˆ† = ç›¸ä¼¼åº¦ Ã— 0.6 
              + æ–°é²œåº¦ Ã— 0.2 
              + æƒå¨æ€§ Ã— 0.1 
              + å®Œæ•´æ€§ Ã— 0.1
    """
    for result in results:
        # åŸºç¡€ç›¸ä¼¼åº¦å¾—åˆ†
        similarity_score = result.score
        
        # æ–°é²œåº¦å¾—åˆ† (è¶Šæ–°è¶Šå¥½)
        days_old = (now - result.created_at).days
        freshness_score = max(0, 1 - days_old / 365)
        
        # æƒå¨æ€§å¾—åˆ† (åŸºäºä½œè€…)
        authority_score = metadata_weights.get(
            result.author, 0.5
        )
        
        # å®Œæ•´æ€§å¾—åˆ† (æ–‡æ¡£é•¿åº¦)
        completeness_score = min(1, len(result.content) / 1000)
        
        # ç»¼åˆå¾—åˆ†
        result.final_score = (
            similarity_score * 0.6 +
            freshness_score * 0.2 +
            authority_score * 0.1 +
            completeness_score * 0.1
        )
    
    # æŒ‰ç»¼åˆå¾—åˆ†æ’åº
    return sorted(results, key=lambda x: x.final_score, reverse=True)
```

---

## ğŸ”„ å®Œæ•´å·¥ä½œæµç¨‹

### 1. ç´¢å¼•æ„å»ºé˜¶æ®µ

```python
from npc_system import RAGTool, RAGConfig

# 1. åˆ›å»ºRAGå·¥å…·
rag = RAGTool(RAGConfig(
    knowledge_base_dir="./knowledge_base/blacksmith",
    index_dir="./rag_index/blacksmith",
    enable_embedding=True
))

# 2. åŠ è½½æ–‡æ¡£
docs = rag.load_documents_from_dir("./knowledge_base/blacksmith/")
print(f"åŠ è½½äº† {len(docs)} ä¸ªæ–‡æ¡£")

# 3. å¤„ç†æ–‡æ¡£ (åˆ†å—)
for doc in docs:
    chunks = rag.chunk_document(doc, chunk_size=500)
    print(f"{doc.doc_id}: {len(chunks)} å—")

# 4. å‘é‡åŒ–
for doc in docs:
    rag.embed_document(doc)
    print(f"{doc.doc_id}: å‘é‡åŒ–å®Œæˆ")

# 5. æ„å»ºç´¢å¼•
rag.build_index()
print("ç´¢å¼•æ„å»ºå®Œæˆ")

# 6. ä¿å­˜ç´¢å¼•
rag.save_index("./rag_index/blacksmith/index.faiss")
print("ç´¢å¼•å·²ä¿å­˜")
```

### 2. æ£€ç´¢é˜¶æ®µ

```python
# 1. åŠ è½½ç´¢å¼•
rag.load_index("./rag_index/blacksmith/index.faiss")

# 2. ç”¨æˆ·æŸ¥è¯¢
query = "å¦‚ä½•é”»é€ é“å‰‘ï¼Ÿ"

# 3. æ£€ç´¢
results = rag.search(query, top_k=3)

# 4. æŸ¥çœ‹ç»“æœ
for i, result in enumerate(results, 1):
    print(f"\\n=== ç»“æœ {i} ===")
    print(f"æ–‡æ¡£: {result.doc_id}")
    print(f"ç›¸ä¼¼åº¦: {result.score:.3f}")
    print(f"å†…å®¹: {result.content[:200]}...")
    print(f"å…ƒæ•°æ®: {result.metadata}")
```

### 3. ç”Ÿæˆé˜¶æ®µ

```python
# 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
context_docs = rag.search("å¦‚ä½•é”»é€ é“å‰‘", top_k=3)

# 2. æ„å»ºä¸Šä¸‹æ–‡
context = "\\n\\n".join([
    f"ã€æ–‡æ¡£{i+1}ã€‘\\n{doc.content}"
    for i, doc in enumerate(context_docs)
])

# 3. æ„å»ºæç¤ºè¯
prompt = f"""åŸºäºä»¥ä¸‹çŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜ã€‚

çŸ¥è¯†åº“:
{context}

é—®é¢˜: å¦‚ä½•é”»é€ é“å‰‘ï¼Ÿ

è¯·åŸºäºçŸ¥è¯†åº“å†…å®¹å›ç­”:"""

# 4. LLMç”Ÿæˆ
response = llm.invoke(prompt)
print(response.content)
```

---

ç»§ç»­é˜…è¯» [06-RAGç³»ç»Ÿè¯¦è§£(ç¬¬2éƒ¨åˆ†)](./06-RAG_SYSTEM_PART2.md)
